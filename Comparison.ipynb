{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Tuning\n",
    "### ToDo\n",
    "* Build a separate run for each tuning parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Goal should be an automated procedure, that tells us what a good amount of won Ausschreibungen is and how diverse the Ausschreibungen should be. That can then further be combined with different kinds of attributes and positive/negative training data ratio. We should build an automated and datadrive test that shows the best tuning parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from db import connection, engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helpers as fdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_an = (\n",
    "    \"anbieter.anbieter_id, \"\n",
    "    \"anbieter.anbieter_plz, \"\n",
    "    \"anbieter.institution as anbieter_institution, \"\n",
    "    \"cpv_dokument.cpv_nummer as anbieter_cpv, \"\n",
    "    \"ausschreibung.meldungsnummer\"\n",
    ")\n",
    "# anbieter_CPV are all the CPVs the Anbieter ever won a procurement for. So all the CPVs they are interested in. \n",
    "select_aus = (\n",
    "    \"anbieter.anbieter_id, \"\n",
    "    \"auftraggeber.institution as beschaffungsstelle_institution, \"\n",
    "    \"auftraggeber.beschaffungsstelle_plz, \"\n",
    "    \"ausschreibung.gatt_wto, \"\n",
    "    \"cpv_dokument.cpv_nummer as ausschreibung_cpv, \"\n",
    "    \"ausschreibung.meldungsnummer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Amout of Public Tenders by Institution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**: A bit early to tell but it looks like about 10 won procurements are needed for a first satisfying result. Although it has to be said that can also be a cooincidence: Once test run takes about 12-14 minutes at the moment so not that many have been conducted since they are very time consuming. We could b etter test for this matter if we would have a fully automated test suite but so far, the low number of 10 sounds promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_an = fdn.getFromSimap(select_an)\n",
    "data_aus = fdn.getFromSimap(select_aus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of Anbieter that have won a different amounts of procurements\n",
    "inst_count = pd.DataFrame(data_an[\"anbieter_institution\"].value_counts())\n",
    "\n",
    "def createInstBin(lower, upper):\n",
    "    return inst_count[(inst_count[\"anbieter_institution\"] >= lower) &(inst_count[\"anbieter_institution\"] <= upper)]\n",
    "\n",
    "# Create different sized bins\n",
    "bin_0_5 = createInstBin(0, 5)\n",
    "bin_5_10 = createInstBin(5, 10)\n",
    "bin_10_15 = createInstBin(10, 15)\n",
    "bin_15_20 = createInstBin(15, 20)\n",
    "bin_20_30 = createInstBin(20, 30)\n",
    "bin_30_40 = createInstBin(30, 40)\n",
    "bin_40_50 = createInstBin(40, 50)\n",
    "bin_50_75 = createInstBin(50, 75)\n",
    "bin_75_100 = createInstBin(75, 100)\n",
    "bin_100_n = inst_count[inst_count[\"anbieter_institution\"] >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createInstBin(150,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick a random sample of one out of each bin to see how different bins perform in the algorithem\n",
    "def chooseFromInstBins(bins):\n",
    "    l = list()\n",
    "    for eachBin in bins:\n",
    "        l.append(eachBin.sample(n=1).index[0])\n",
    "    return l\n",
    "\n",
    "institutionList = chooseFromInstBins(\n",
    "    [bin_0_5,\n",
    "    bin_5_10,\n",
    "    bin_10_15,\n",
    "    bin_15_20,\n",
    "    bin_20_30,\n",
    "    bin_30_40,\n",
    "    bin_40_50,\n",
    "    bin_50_75,\n",
    "    bin_75_100,\n",
    "    bin_100_n])\n",
    "\n",
    "institutionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def treeRunPerSize(instList):\n",
    "    start_time = time.time()\n",
    "    results = [];\n",
    "    for inst in instList:\n",
    "        df_pos_full, df_neg_full = fdn.createAnbieterDf(select_an, select_aus, inst)\n",
    "        x, y, z = fdn.decisionTreeRun(df_pos_full, df_neg_full , len(df_pos_full)*2)\n",
    "        results.append([x, y, z])\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return results, elapsed_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t = treeRunPerSize(institutionList)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in v:\n",
    "    print(e[1])\n",
    "for e in v:\n",
    "    print(e[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Amount of CPV Diversity of Institution\n",
    "Do the same with CPV Diversitiy fdn.getCpvCount('Swisscom')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn.getCpvDiversity('Swisscom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**: This sort of analysis should be done at a later stage, when we have a full test suite and can repeatatly train a model on different data samples. We then can then investigate the inpact of CPV deversity of a subject (Anbieter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Run (multiple runs)\n",
    "### ToDo\n",
    "* Try with Random Forest\n",
    "* Add other attributes (generic, so we are able to test which work best)\n",
    "* Add optimal Tender and CPV Amount (see above)\n",
    "* Extend Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with all negative and all positive respones for a specific Anbieter\n",
    "df_pos_full, df_neg_full = fdn.createAnbieterDf(select_an, select_aus, \"Adecco AG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_count = len(df_pos_full)\n",
    "step = math.ceil(positives_count / 10)\n",
    "max_negative_count = step * 100\n",
    "print(positives_count, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO insert for 50000 --> len(df_neg_full) modulo...\n",
    "\n",
    "positives_count = len(df_pos_full)\n",
    "step = math.ceil(positives_count / 10)\n",
    "max_negative_count = step * 100\n",
    "\n",
    "# Create list placeholders\n",
    "precision, pos_neg_ratio, confusion_matrices, fns, fps = ([] for i in range(5))\n",
    "\n",
    "# run the decison tree multiple times\n",
    "for i in range(positives_count, max_negative_count, step):\n",
    "    x, y, z = fdn.decisionTreeRun(df_pos_full, df_neg_full , i)\n",
    "    precision.append(x)\n",
    "    pos_neg_ratio.append(y)\n",
    "    confusion_matrices.append(z)\n",
    "    fns.append(z[1][0])\n",
    "    fps.append(z[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of positive to negtive Datapoints Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**: You can see a positive linear trend in False Positives (FPS) and False Negatives (FNS) with increasing share of negative data points used. While one might think it is better to keep the negatives low to reduce them. However the reason is most likely that in a bigger negative pool there are likely more similar procurements that could considered positives. So these FPS could be procurements in which the bidder might actually be interested in.\n",
    "As for the rising amount of FNS: If there are very few positves in the test set, and the trainig might get more inacurate if by bad luck lots of the positives get put in the test set and not in the training set.\n",
    "*Conclusion*: Postives should probably not make less than 25% of the test set.\n",
    "*Try Suggestion*: The negatives in test and traiing set should be of more similar range concerning the CPVs to train more accuratly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display False Negatives\n",
    "print(positives_count)\n",
    "plt.plot(range(positives_count, max_negative_count, step), fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display False Positives\n",
    "print(positives_count)\n",
    "plt.plot(range(positives_count, max_negative_count, step), fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Look at the indiviual ones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Suite\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from db import connection, engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helpers as fdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your pandas version is 0.23.1. Please use version 0.23.1\n",
      "Your numpy version is 1.13.1. Please use version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "print('Your pandas version is {}. Please use version 0.23.1'.format(pd.__version__))\n",
    "print('Your numpy version is {}. Please use version 1.13.1'.format(np.__version__))\n",
    "# import sklearn\n",
    "# print('The scikit-learn version is {}. Please use version 0.20.1'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Attributes\n",
    "def cleanData(df, filters):\n",
    "    if 'beschaffungsstelle_plz' in filters:\n",
    "        df[['beschaffungsstelle_plz']] = df[['beschaffungsstelle_plz']].applymap(fdn.tonumeric)\n",
    "    if 'gatt_wto' in filters:\n",
    "        df[['gatt_wto']] = df[['gatt_wto']].applymap(fdn.unifyYesNo)\n",
    "    if 'preis' in filters:\n",
    "        df[['preis']] = df[['preis']].applymap(fdn.createPriceCategory)\n",
    "    if 'anzahl_angebote' in filters:\n",
    "        df[['anzahl_angebote']] = df[['anzahl_angebote']].applymap(fdn.tonumeric)\n",
    "    if 'teilangebote' in filters:\n",
    "        df[['teilangebote']] = df[['teilangebote']].applymap(fdn.unifyYesNo)\n",
    "    if 'lose' in filters:\n",
    "        df[['lose']] = df[['lose']].applymap(fdn.unifyYesNo)\n",
    "    if 'varianten' in filters:\n",
    "        df[['varianten']] = df[['varianten']].applymap(fdn.unifyYesNo)\n",
    "    if 'projekt_titel' in filters:\n",
    "        vectorizer = CountVectorizer(binary=True)\n",
    "        X = vectorizer.fit_transform(df['projekt_titel'].values)\n",
    "        text_columns = vectorizer.get_feature_names()\n",
    "        title_df = pd.DataFrame(X.todense(), columns=text_columns)\n",
    "        df = pd.concat([df, title_df], axis=1)\n",
    "        df = df.drop('projekt_titel', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareForRun(df_pos, df_neg_all, filterAttributes):\n",
    "    # What attributes the model will be trained by\n",
    "    filters = ['Y', 'ausschreibung_cpv'] + filterAttributes\n",
    "    df_ready_all = []\n",
    "    for df_neg in df_neg_all:\n",
    "        # Merge positive and negative df into one, only use selected attributes\n",
    "        df_tmp = df_pos.append(df_neg, ignore_index=True)[filters].copy()\n",
    "        # Clean the data of all selected attributes\n",
    "        df_tmp = cleanData(df_tmp, filterAttributes)\n",
    "        df_ready_all.append(df_tmp)\n",
    "    return df_ready_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDecisionTree(dataFrame, trees, depth):\n",
    "    xTests = [];\n",
    "    yTests = [];\n",
    "    for idx, df in enumerate(dataFrame): # enum to get index\n",
    "        df\n",
    "        run = shuffle(df)\n",
    "        # Put responses in one arry and all diesired properties in another\n",
    "        y = run.iloc[:, 0]\n",
    "        x = run.iloc[:, 1:] # Every column but the first\n",
    "        # create sets\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25)\n",
    "        # train the model on training sets\n",
    "    #    clf = tree.DecisionTreeClassifier()\n",
    "        clf = RandomForestClassifier(n_estimators=trees, max_depth=depth, random_state=0)\n",
    "        clf = clf.fit(xtrain, ytrain)\n",
    "        print(clf.score(xtrain, ytrain))    # TODO: Explain\n",
    "        # predict on the test sets\n",
    "        prediction = clf.predict(xtest)\n",
    "        # pandas.series to data frame\n",
    "        df_ytest = ytest.to_frame()\n",
    "        # add run number to df\n",
    "        df_ytest['run'] = idx\n",
    "        xtest['run'] = idx\n",
    "        # add prediction to df\n",
    "        df_ytest['prediction']= prediction\n",
    "        # add result of run to df\n",
    "        df_ytest['correct'] = df_ytest['prediction']==df_ytest['Y']\n",
    "        # add run to run arrays\n",
    "        xTests.append(xtest)\n",
    "        yTests.append(df_ytest)\n",
    "    return xTests, yTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracies(dfys):  \n",
    "    res = pd.DataFrame(columns=['accuracy', 'f1_score', 'fn rate'])\n",
    "    for dfy in dfys:\n",
    "        acc = round(accuracy_score(dfy.Y, dfy.prediction), 4)\n",
    "        f1 = round(f1_score(dfy.Y, dfy.prediction), 4)\n",
    "        cm = confusion_matrix(dfy.Y, dfy.prediction)\n",
    "        fnr = round(cm[1][0] / (cm[0][0] + cm[1][0]), 4)   # TODO: Double check if correct\n",
    "        res.loc[len(res)] = [ acc*100, f1*100, fnr*100 ] # add row to end of df, *100 for better % readability\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatices(dfys):  \n",
    "    res = pd.DataFrame(columns=['tn', 'tp', 'fp', 'fn'])\n",
    "    for dfy in dfys:\n",
    "        # ConfusionMatrix legende:\n",
    "        # [tn, fp]\n",
    "        # [fn, tp]\n",
    "        cm = confusion_matrix(dfy.Y, dfy.prediction)\n",
    "        res.loc[len(res)] = [ cm[0][0], cm[1][1], cm[0][1], cm[1][0] ]\n",
    "    res.loc['sum'] = res.sum() # Summarize each column\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Institution & Get Data\n",
    "Only needs to be done once per bidder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a bidder to train a model for (number of positive marked after the name)\n",
    "\n",
    "#anbieter = 'Arnold AG' #1006\n",
    "#anbieter = 'Alpiq AG' #827\n",
    "#anbieter = 'Siemens AG' #641\n",
    "anbieter = 'Marti AG' #621\n",
    "#anbieter = 'Swisscom' #602\n",
    "#anbieter = 'Axpo AG' #577\n",
    "#anbieter = 'Hewlett-Packard' #155\n",
    "#anbieter = 'BG Ing√©nieurs Conseils' SA #151\n",
    "#anbieter = 'Pricewaterhousecoopers' # 92\n",
    "#anbieter = 'Helbling Beratung + Bauplanung AG' #67\n",
    "#anbieter = 'Ofrex SA' #40\n",
    "#anbieter = 'PENTAG Informatik AG' #40\n",
    "#anbieter = 'Wicki Forst AG' #30\n",
    "#anbieter = 'T-Systems Schweiz' #30\n",
    "#anbieter = 'Bafilco AG' #20\n",
    "#anbieter = '4Video-Production GmbH' #20\n",
    "#anbieter = 'Widmer Ingenieure AG' #10\n",
    "#anbieter = 'hmb partners AG' #10\n",
    "#anbieter = 'Planmeca' #5\n",
    "#anbieter = 'K & M Installationen AG' #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_anbieter = (\n",
    "    \"anbieter.anbieter_id, \"\n",
    "    \"anbieter.institution as anbieter_institution, \"\n",
    "    \"cpv_dokument.cpv_nummer as anbieter_cpv, \"\n",
    "    \"ausschreibung.meldungsnummer\"\n",
    ")\n",
    "# anbieter_CPV are all the CPVs the Anbieter ever won a procurement for. So all the CPVs they are interested in. \n",
    "select_ausschreibung = (\n",
    "    \"anbieter.anbieter_id, \"\n",
    "    \"auftraggeber.institution as beschaffungsstelle_institution, \"\n",
    "    \"auftraggeber.beschaffungsstelle_plz, \"\n",
    "    \"ausschreibung.gatt_wto, \"\n",
    "    \"ausschreibung.sprache, \"\n",
    "    \"ausschreibung.auftragsart_art, \"\n",
    "    \"ausschreibung.lose, \"\n",
    "    \"ausschreibung.teilangebote, \"\n",
    "    \"ausschreibung.varianten, \"\n",
    "  #  \"ausschreibung.titel, \" TODO: Projektbeschrieb\n",
    "    \"ausschreibung.bietergemeinschaft, \"\n",
    "    \"projekt.projekt_titel, \"\n",
    "    \"cpv_dokument.cpv_nummer as ausschreibung_cpv, \"\n",
    "    \"ausschreibung.meldungsnummer\"\n",
    ")\n",
    "# Get all positive and negative responses\n",
    "responses_positive, full_negative = fdn.createAnbieterDf(select_anbieter, select_ausschreibung, anbieter)\n",
    "responses_positive.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***ToDo:***\n",
    "* TEST WITH BIDDERS OF DIFFERENT SIZE!\n",
    "* Add Auftrags_art as catagory!!\n",
    "* Create function to read all which tenderings are FPs / FNs\n",
    "* Create a n times n input for all attributes\n",
    "* Test with Random Forest\n",
    "* Enable better auto Evaluation Feedback. Maybe some Graphs or something\n",
    "* Prepare (and test with) more Attributes\n",
    "* Test Model only with Tenderings from the same ream / CPV category\n",
    "* (\"ctrl + F\" all TODOs in this file)\n",
    "* (Take a look at warning when tree is run)\n",
    "\n",
    "***Fragen:***\n",
    "* M√ºssen wir die Freih√§nder beachten?\n",
    "* Spielen Attribute des Zuschlags √ºberhaupt eine Rolle?\n",
    "* Welche Attribute wollen wir noch anschauen / einbringen?\n",
    "* Wenn wir nur den CPV verwenden, ist die Anwendung besser als ein normaler Filter?\n",
    "* K√∂nnte unser Algorithmus einen Bias haben, da wir mehrer CPV miteinander kombinieren, wenn wir die Tables laden?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†ratio that the positive and negative responses have to each other\n",
    "positive_to_negative_ratio = 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train n different models on n different (reproducable) sample sizes\n",
    "runs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes ready for use: 'beschaffungsstelle_plz', 'gatt_wto', 'lose', 'teilangebote', 'varianten'\n",
    "\n",
    "# Next focus: 'beschaffungsstelle_institution', 'titel', 'sprache', 'auftragsart_art' <-- AUFTRAGSART!\n",
    "\n",
    "# ???: 'Preis', 'anzahl_angebote'\n",
    "\n",
    "attributes = ['beschaffungsstelle_plz', 'gatt_wto', 'lose', 'teilangebote', 'varianten', 'projekt_titel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Random Forest Parameter\n",
    "trees = 100\n",
    "depth = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†create the chosen amount reproducable samples for negative DataFrames with the ratio definded above\n",
    "responses_negative_all = fdn.createNegativeResponses(\n",
    "    full_negative,\n",
    "    len(responses_positive),\n",
    "    runs,\n",
    "    positive_to_negative_ratio)\n",
    "\n",
    "# Assign positive and negative lables to both DFs\n",
    "responses_positive['Y'] = 1\n",
    "for df in responses_negative_all:\n",
    "    df['Y'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9726315789473684\n",
      "0.9636842105263158\n",
      "0.9768421052631578\n",
      "0.9736842105263158\n",
      "0.968421052631579\n",
      "0.9647368421052631\n",
      "0.9689473684210527\n",
      "0.9673684210526315\n",
      "0.9642105263157895\n",
      "0.9573684210526315\n",
      "0.978421052631579\n",
      "0.9731578947368421\n",
      "0.9742105263157895\n",
      "0.9636842105263158\n",
      "0.9747368421052631\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # hide some \"slice of copy\" warnings\n",
    "df_for_decision_tree = prepareForRun(responses_positive, responses_negative_all, attributes)\n",
    "xTests, yTests = runDecisionTree(df_for_decision_tree, trees, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>attribute_count</th>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "attribute_count  2663"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = {\n",
    "    'attribute_count': len(df_for_decision_tree[0].columns),\n",
    "}\n",
    "\n",
    "pd.DataFrame.from_dict(stats, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>396</td>\n",
       "      <td>206</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>201</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>381</td>\n",
       "      <td>222</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371</td>\n",
       "      <td>234</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363</td>\n",
       "      <td>245</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>236</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>384</td>\n",
       "      <td>220</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>407</td>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>393</td>\n",
       "      <td>217</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>386</td>\n",
       "      <td>215</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>379</td>\n",
       "      <td>220</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>380</td>\n",
       "      <td>218</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>360</td>\n",
       "      <td>236</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>364</td>\n",
       "      <td>232</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>376</td>\n",
       "      <td>233</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>5719</td>\n",
       "      <td>3337</td>\n",
       "      <td>197</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tn    tp   fp   fn\n",
       "0     396   206   17   15\n",
       "1     404   201   12   17\n",
       "2     381   222   13   18\n",
       "3     371   234   15   14\n",
       "4     363   245   13   13\n",
       "5     375   236   10   13\n",
       "6     384   220   11   19\n",
       "7     407   202   14   11\n",
       "8     393   217   13   11\n",
       "9     386   215    6   27\n",
       "10    379   220   21   14\n",
       "11    380   218   14   22\n",
       "12    360   236   17   21\n",
       "13    364   232    9   29\n",
       "14    376   233   12   13\n",
       "sum  5719  3337  197  257"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getConfusionMatices(yTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beschaffungsstelle_plz', 'gatt_wto', 'lose', 'teilangebote', 'varianten', 'projekt_titel']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fn rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.22</td>\n",
       "      <td>91.06</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.43</td>\n",
       "      <td>93.68</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.53</td>\n",
       "      <td>95.26</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.27</td>\n",
       "      <td>93.48</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.74</td>\n",
       "      <td>94.67</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95.11</td>\n",
       "      <td>92.67</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94.16</td>\n",
       "      <td>92.70</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95.27</td>\n",
       "      <td>93.62</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94.16</td>\n",
       "      <td>92.04</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95.27</td>\n",
       "      <td>94.02</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>95.58</td>\n",
       "      <td>93.86</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>96.69</td>\n",
       "      <td>95.62</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>97.00</td>\n",
       "      <td>96.03</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>93.38</td>\n",
       "      <td>90.75</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>95.11</td>\n",
       "      <td>93.76</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score  fn rate\n",
       "0      93.22     91.06     6.77\n",
       "1      95.43     93.68     3.47\n",
       "2      96.53     95.26     3.22\n",
       "3      95.27     93.48     2.26\n",
       "4      95.74     94.67     1.87\n",
       "5      95.11     92.67     4.01\n",
       "6      94.16     92.70     5.48\n",
       "7      95.27     93.62     3.27\n",
       "8      94.16     92.04     2.79\n",
       "9      95.27     94.02     3.92\n",
       "10     95.58     93.86     2.97\n",
       "11     96.69     95.62     3.03\n",
       "12     97.00     96.03     2.78\n",
       "13     93.38     90.75     5.39\n",
       "14     95.11     93.76     4.39"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(attributes)\n",
    "getAccuracies(yTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

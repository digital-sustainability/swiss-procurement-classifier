{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Suite Final\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from db import connection, engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helpers as fdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My pandas version is {}. Please use version 0.23.1'.format(pd.__version__))\n",
    "print('My numpy version is {}. Please use version 1.13.1'.format(np.__version__))\n",
    "# import sklearn\n",
    "# print('The scikit-learn version is {}. Please use version 0.20.1'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Attributes\n",
    "def cleanData(df, filters):\n",
    "    if 'beschaffungsstelle_plz' in filters:\n",
    "        df[['beschaffungsstelle_plz']] = df[['beschaffungsstelle_plz']].applymap(fdn.tonumeric)\n",
    "    if 'gatt_wto' in filters:\n",
    "        df[['gatt_wto']] = df[['gatt_wto']].applymap(fdn.unifyYesNo)\n",
    "    if 'preis' in filters:\n",
    "        df[['preis']] = df[['preis']].applymap(fdn.createPriceCategory)\n",
    "    if 'anzahl_angebote' in filters:\n",
    "        df[['anzahl_angebote']] = df[['anzahl_angebote']].applymap(fdn.tonumeric)\n",
    "    if 'teilangebote' in filters:\n",
    "        df[['teilangebote']] = df[['teilangebote']].applymap(fdn.unifyYesNo)\n",
    "    if 'lose' in filters:\n",
    "        df[['lose']] = df[['lose']].applymap(fdn.unifyYesNo)\n",
    "    if 'varianten' in filters:\n",
    "        df[['varianten']] = df[['varianten']].applymap(fdn.unifyYesNo)\n",
    "    if 'auftragsart_art' in filters:\n",
    "        auftrags_art_df = pd.get_dummies(df['auftragsart_art'], prefix='aftrgsrt',dummy_na=True)\n",
    "        df = pd.concat([df,auftrags_art_df],axis=1).drop(['auftragsart_art'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareForRun(df_pos, df_neg_all, filterAttributes):\n",
    "    # What attributes the model will be trained by\n",
    "    filters = ['Y', 'meldungsnummer', 'ausschreibung_cpv'] + filterAttributes\n",
    "    df_ready_all = []\n",
    "    for df_neg in df_neg_all:\n",
    "        # Merge positive and negative df into one, only use selected attributes\n",
    "        df_tmp = df_pos.append(df_neg, ignore_index=True)[filters].copy()\n",
    "        # Clean the data of all selected attributes\n",
    "        df_tmp = cleanData(df_tmp, filterAttributes)\n",
    "        df_ready_all.append(df_tmp)\n",
    "    return  df_ready_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareUnfilteredRun(df_pos, df_neg_all, filterAttributes):\n",
    "    df_all = []\n",
    "    for df_neg in df_neg_all:\n",
    "        # Merge positive and negative df into one\n",
    "        df_all.append(df_pos.append(df_neg, ignore_index=True).copy())\n",
    "    return  df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDecisionTree(dataFrame, trees, depth, test_size):\n",
    "    xTests = [];\n",
    "    yTests = [];\n",
    "    for idx, df in enumerate(dataFrame): # enum to get index\n",
    "        # Unique df where positives are appended to negatives -> Shuffle\n",
    "        run = shuffle(df, random_state=idx) # run index as random state\n",
    "        # Get each runs unique meldungsnummer\n",
    "        unique_mn = run.meldungsnummer.unique()\n",
    "        # Split the meldungsnummer between test and trainings set so there will be no bias in test set\n",
    "        xUniqueTest, xUniqueTrain = train_test_split(unique_mn, test_size=test_size, random_state=idx)\n",
    "        # Add the remaining attributes to meldungsnummer\n",
    "        xAndYTest = run[run['meldungsnummer'].isin(xUniqueTest)].copy()\n",
    "        xAndYTrain = run[run['meldungsnummer'].isin(xUniqueTrain)].copy()\n",
    "        # Select all attributes but meldungsnummer\n",
    "        xtest = xAndYTest.iloc[:, 2:]\n",
    "        xtrain = xAndYTrain.iloc[:, 2:]\n",
    "        # Only select the response result attributes\n",
    "        ytest = xAndYTest.iloc[:, 0]\n",
    "        ytrain = xAndYTrain.iloc[:, 0]\n",
    "        # Train the model on training sets\n",
    "        #clf = tree.DecisionTreeClassifier()\n",
    "        clf = RandomForestClassifier(n_estimators=trees, max_depth=depth, random_state=idx) # run index as random state\n",
    "        clf = clf.fit(xtrain, ytrain)\n",
    "        # Predict on the test sets\n",
    "        prediction = clf.predict(xtest)\n",
    "        # Convert pandas.series to data frame\n",
    "        df_ytest = ytest.to_frame()\n",
    "        # Add run number to df\n",
    "        df_ytest['run'] = idx\n",
    "        xtest['run'] = idx\n",
    "        # add prediction to df\n",
    "        df_ytest['prediction']= prediction\n",
    "        # add result of run to df\n",
    "        df_ytest['correct'] = df_ytest['prediction']==df_ytest['Y']\n",
    "        # add run to run arrays\n",
    "        xTests.append(xtest)\n",
    "        yTests.append(df_ytest)\n",
    "        print('Finished run {}'.format(idx))\n",
    "        if idx == 19:\n",
    "            print(len(run))\n",
    "            print(len(unique_mn))\n",
    "            print(len(xtest))\n",
    "            print(len(xTests[19]))\n",
    "    return xTests, yTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracies(dfys):  \n",
    "    res = pd.DataFrame(columns=['accuracy', 'MCC', 'fn rate'])\n",
    "    for dfy in dfys:\n",
    "        acc = round(accuracy_score(dfy.Y, dfy.prediction), 4)\n",
    "        #f1 = round(f1_score(dfy.Y, dfy.prediction), 4)\n",
    "        mcc = matthews_corrcoef(dfy.Y, dfy.prediction)\n",
    "        cm = confusion_matrix(dfy.Y, dfy.prediction)\n",
    "        fnr = round(cm[1][0] / (cm[1][1] + cm[1][0]), 4)\n",
    "        res.loc[len(res)] = [ acc*100, mcc, fnr*100 ] # add row to end of df, *100 for better % readability\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProjectTitle(meldungsnummer):\n",
    "    query = \"\"\"\n",
    "    select projekt.projekt_titel from projekt, ausschreibung, cpv_dokument\n",
    "    where projekt.projekt_id = ausschreibung.projekt_id\n",
    "      and ausschreibung.meldungsnummer = cpv_dokument.meldungsnummer\n",
    "      and ausschreibung.meldungsnummer = \"{}\";\n",
    "    \"\"\".format(meldungsnummer)\n",
    "    return pd.read_sql(query, connection);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatices(dfys):  \n",
    "    res = pd.DataFrame(columns=['tn', 'tp', 'fp', 'fn'])\n",
    "    for dfy in dfys:\n",
    "        # ConfusionMatrix legende:\n",
    "        # [tn, fp]\n",
    "        # [fn, tp]\n",
    "        cm = confusion_matrix(dfy.Y, dfy.prediction)\n",
    "        res.loc[len(res)] = [ cm[0][0], cm[1][1], cm[0][1], cm[1][0] ]\n",
    "    res.loc['sum'] = res.sum() # Summarize each column\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns as data frame with all FalseNegatives or FalsePositives\n",
    "def getFalseFullList(positive, originalRuns, runs, run):\n",
    "    # Get FalsePositives\n",
    "    if (positive):\n",
    "        idxs = runs[run][(runs[run]['Y'] == 0) & (runs[run]['prediction'] == 1)].index.tolist()\n",
    "    # Get FalseNegatives\n",
    "    else:\n",
    "        idxs = runs[run][(runs[run]['Y'] == 1) & (runs[run]['prediction'] == 0)].index.tolist()\n",
    "    return originalRuns[run].ix[idxs]\n",
    "\n",
    "# Prints the project titles of eitehr FalsePositives or FalseNegatives\n",
    "def getFalseProjectTitle(positive, originalRuns, runs, run):\n",
    "    for m in getFalseFullList(positive, originalRuns, runs, run).meldungsnummer:\n",
    "        print(getProjectTitle(m))\n",
    "        print('========') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Institution & Get Data\n",
    "Only needs to be done once per bidder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a bidder to train a model for (number of positive marked after the name)\n",
    "\n",
    "#anbieter = 'Arnold AG' #1006\n",
    "#anbieter = 'Alpiq AG' #827\n",
    "#anbieter = 'Siemens AG' #641\n",
    "#anbieter = 'Marti AG' #621\n",
    "#anbieter = 'Swisscom' #602\n",
    "#anbieter = 'Axpo AG' #577\n",
    "#anbieter = 'Hewlett-Packard' #155\n",
    "#anbieter = 'BG Ingénieurs Conseils' SA #151\n",
    "#anbieter = 'Pricewaterhousecoopers' # 92\n",
    "anbieter = 'Helbling Beratung + Bauplanung AG' #67\n",
    "#anbieter = 'Ofrex SA' #40\n",
    "#anbieter = 'PENTAG Informatik AG' #40\n",
    "#anbieter = 'Wicki Forst AG' #30\n",
    "#anbieter = 'T-Systems Schweiz' #30\n",
    "#anbieter = 'Bafilco AG' #20\n",
    "#anbieter = '4Video-Production GmbH' #20\n",
    "#anbieter = 'Widmer Ingenieure AG' #10\n",
    "#anbieter = 'hmb partners AG' #10\n",
    "#anbieter = 'Planmeca' #5\n",
    "#anbieter = 'K & M Installationen AG' #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_anbieter = (\n",
    "    \"anbieter.anbieter_id, \"\n",
    "    \"anbieter.institution as anbieter_institution, \"\n",
    "    \"cpv_dokument.cpv_nummer as anbieter_cpv, \"\n",
    "    \"ausschreibung.meldungsnummer\"\n",
    ")\n",
    "# anbieter_CPV are all the CPVs the Anbieter ever won a procurement for. So all the CPVs they are interested in. \n",
    "select_ausschreibung = (\n",
    "    \"anbieter.anbieter_id, \"\n",
    "    \"auftraggeber.institution as beschaffungsstelle_institution, \"\n",
    "    \"auftraggeber.beschaffungsstelle_plz, \"\n",
    "    \"ausschreibung.gatt_wto, \"\n",
    "    \"ausschreibung.sprache, \"\n",
    "    \"ausschreibung.auftragsart_art, \"\n",
    "    \"ausschreibung.lose, \"\n",
    "    \"ausschreibung.teilangebote, \"\n",
    "    \"ausschreibung.varianten, \"\n",
    "   # \"ausschreibung.titel, \"\n",
    "    \"ausschreibung.bietergemeinschaft, \"\n",
    "    \"cpv_dokument.cpv_nummer as ausschreibung_cpv, \"\n",
    "    \"ausschreibung.meldungsnummer as meldungsnummer2\"\n",
    ")\n",
    "# Get all positive and negative responses\n",
    "responses_positive, full_negative = fdn.createAnbieterDf(select_anbieter, select_ausschreibung, anbieter)\n",
    "print('Number of Rows: {}'.format(len(responses_positive)))\n",
    "responses_positive.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***ToDo:***\n",
    "* TEST WITH BIDDERS OF DIFFERENT SIZE!\n",
    "* Create a n times n input for all attributes\n",
    "* Enable better auto Evaluation Feedback. Maybe some Graphs or something\n",
    "* Test Model only with Tenderings from the same ream / CPV category\n",
    "* (\"ctrl + F\" all TODOs in this file)\n",
    "* (Take a look at warning when tree is run)\n",
    "\n",
    "***Fragen:***\n",
    "* Müssen wir die Freihänder beachten?\n",
    "* Gibt es mehrere Ausschreibungen pro Meldungsnummer?\n",
    "* Wenn wir nur den CPV verwenden, ist die Anwendung besser als ein normaler Filter?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio that the positive and negative responses have to each other\n",
    "positive_to_negative_ratio = 2/3\n",
    "# Percentage of training set that is used for testing (Recommendation of at least 25%)\n",
    "test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train n different models on n different (reproducable) sample sizes\n",
    "runs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes ready for use: 'beschaffungsstelle_plz', 'gatt_wto', 'lose', 'teilangebote', 'varianten'\n",
    "\n",
    "# Next focus: 'beschaffungsstelle_institution', 'titel', 'sprache', 'auftragsart_art' <-- AUFTRAGSART!\n",
    "\n",
    "# ???: 'Preis', 'anzahl_angebote'\n",
    "\n",
    "attributes = ['beschaffungsstelle_plz', 'auftragsart_art']\n",
    "#attributes = [ 'gatt_wto', 'lose', 'teilangebote', 'varianten', 'beschaffungsstelle_plz']\n",
    "attributes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Random Forest Parameter\n",
    "trees = 100\n",
    "depth = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chosen amount of reproducable samples for negative DataFrames with the ratio definded above\n",
    "responses_negative_all = fdn.createNegativeResponses(\n",
    "    full_negative,\n",
    "    len(responses_positive),\n",
    "    runs,\n",
    "    positive_to_negative_ratio)\n",
    "\n",
    "# Assign positive and negative lables to both DFs\n",
    "responses_positive['Y'] = 1\n",
    "for df in responses_negative_all:\n",
    "    df['Y'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = prepareForRun(responses_positive, responses_negative_all, attributes)\n",
    "dataFrameRaw = prepareUnfilteredRun(responses_positive, responses_negative_all, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pls delete\n",
    "test_df = next(enumerate(dataFrame))[1]\n",
    "test_df.describe()\n",
    "responses_negative_all[5].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # hide some \"slice of copy\" warnings\n",
    "xTests, yTests = runDecisionTree(dataFrame,\n",
    "                                 trees,\n",
    "                                 depth,\n",
    "                                 test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attributes)\n",
    "evaluation_matirx = pd.concat([getConfusionMatices(yTests), getAccuracies(yTests)], axis=1, sort=False)\n",
    "print(evaluation_matirx[\"accuracy\"].mean())\n",
    "evaluation_matirx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show FalsePositive (Run as last parameter)\n",
    "getFalseFullList(True, dataFrameRaw, yTests, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show FalseNegatives (Run as last parameter)\n",
    "getFalseFullList(False, dataFrameRaw, yTests, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Project Titles of FalsePositves (Run as last parameter)\n",
    "getFalseProjectTitle(True, dataFrameRaw, yTests, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Project Titles of FalseNegatives (Run as last parameter)\n",
    "getFalseProjectTitle(False, dataFrameRaw, yTests, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn.getCpvDiversity('Helbling Beratung + Bauplanung AG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn.getCpvCount('Arnold AG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anbieter = 'Arnold AG' #1006\n",
    "#anbieter = 'Alpiq AG' #827\n",
    "#anbieter = 'Siemens AG' #641\n",
    "#anbieter = 'Marti AG' #621\n",
    "#anbieter = 'Swisscom' #602\n",
    "#anbieter = 'Axpo AG' #577\n",
    "#anbieter = 'Hewlett-Packard' #155\n",
    "#anbieter = 'BG Ingénieurs Conseils' SA #151\n",
    "#anbieter = 'Pricewaterhousecoopers' # 92\n",
    "#anbieter = 'Helbling Beratung + Bauplanung AG' #67\n",
    "#anbieter = 'Ofrex SA' #40\n",
    "#anbieter = 'PENTAG Informatik AG' #40\n",
    "#anbieter = 'Wicki Forst AG' #30\n",
    "#anbieter = 'T-Systems Schweiz' #30\n",
    "#anbieter = 'Bafilco AG' #20\n",
    "#anbieter = '4Video-Production GmbH' #20\n",
    "#anbieter = 'Widmer Ingenieure AG' #10\n",
    "#anbieter = 'hmb partners AG' #10\n",
    "#anbieter = 'Planmeca' #5\n",
    "#anbieter = 'K & M Installationen AG' #5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
